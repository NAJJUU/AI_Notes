1. 간단한 역사
    1) 초기 머신 러닝
        - 퍼셉트론(perceptron)과 이와 관련된 알고리즘
            - AI를 설계하기 위해 생물학적 뇌 동작하는 방식을
              이해하려는 시도
            - 뇌의 뉴런 개념을 발표
            - 뉴런들은 뇌의 신경 세포와 서로 연결되어 있음
            - 화학적, 전기적 신호를 처리하고 전달하는 데 관여함
        
        - 신경 세포를 이진 출력을 내는 간단한 논리 회로로 표현
            - 수상 돌기에 여러 신호가 도착하면 세포체에 합쳐짐
            - 합쳐진 신호가 특정 임계 값을 넘으면
              출력 신호가 생성되고 축삭 돌기를 이용하여 전달
        
        - 자동으로 최적의 가중치를 학습하는 알고리즘을 제안
            - 퍼셉트론 규칙
            - 이 가중치는 뉴런의 출력 신호를 낼지 말지를
              결정하기 위해 입력 특성에 곱하는 계수임
    
    2) 인공 뉴런(Artificial Neural)의 수학적 정의
        - 입력 값 x와 이에 상응하는 가중치 벡터 w의
          선형 조합으로 정의
        - 최종 입력
            - w1x1 + w2x2 + ... wnxn



        

2. 퍼셉트론 학습 알고리즘 구현

3. 통계학과 확률
    1) 통계학
        -데이터를 연구하는 학문
        -규칙성 발견, 객관적 의사결정
    2) 확률
        -조건이 중요한 사건
            -ex) 기온이 영하 12도일 때 눈이 내릴 확률
                 본인이 코로나 양성일 때 주변인이 감염될 확률
    3) 조건부 확률
        -사건 B가 일어난 상황에서 사건 A가 일어날 확률
        -P(A|B)
    4) 뇌과학 
        -뉴런의 정보처리 과정이 베이즈 정리를 따른다고 주장
    5) 머신러닝 
        -베이즈 확률을 계산하기 위한 도구
        -수학적 모델 설계 
        -데이터 분석을 통해 수학적 모델을 수정함(학습)
        -컴퓨터 성능의 발전이 머신러닝 기법 발전을 가속화함
        -현재 거의 모든 산업 분야에서 머신러닝 활용 중 
    6) 퍼셉트론(인공신경)
        -뇌세포를 모방한 기계
        -딥러닝은 가중치(Wn)를 수정하는 행위
        -자극->함수->출력
        -활성화 함수
            A 
                뉴런 10개 
                            C
                뉴런 50개
            B 
            -뇌세포는 항상 일정한 크기의 값을 출력함 (0 or 1)
            -뇌세포의 출력물을 디지털 신호로 간주할 수 있음
            -인간의 뇌를 흉내내려면 출력값의 형태 또한 흉내내야 함 
            -종류
                -Sigmoid 함수  
                    -가장 무난한 형태로 널리 활용됨
                -Tanh 함수
                    -Sigmoid에 비해 뉴런의 On-Off를 더 잘 흉내냄 
                    -최근 음수값을 사용하지 않으려는 추세로 선호도가 낮아짐
                -ReLU 함수
                    -딥러닝 성능을 크게 향상시키는 경향이 있어 널리 활용됨
                -Leakey ReLU 함수
                    -음수값 정보가 일부 보전되어 간혹 ReLU보다 성능이 뛰어남
    7) 인공신경망
        -인공 신경(퍼셉트론)을 그물처럼 쌓아올린 것
        -퍼셉트론들이 모여 한 층의 신경망이 됨 
    8) 딥러닝 
        -인공신경망을 여러 층으로 쌓아 올리는 행위
        -퍼셉트론층(은닉층, hidden layer)을 차곡차곡 쌓아 올려 다층의 신경망을 제작함
        -신경망을 깊은 층으로 쌓는 행위를 딥러닝이라 부름

4. 딥러닝(Deep Learning)
    1) 사용하는 이유
        -인간의 뇌를 흉내낸 인공지능의 성능을 높이기 위해 사용
        -Feedforward Neural Network(FNN)의 구조
            -퍼셉트론이 역여서 만들어진 구물같은 구조가 결합하여 형성됨
    2) 역전파(Backpropagation)
        -역전파 기법으로 은닉층 학습이 가능해져 딥러닝 연구가 본격적으로 시작됨